% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.1 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{measurement_1995}{book}{}
      \name{author}{1}{}{%
        {{hash=ee09f9fdfe615feaeca2f154e1c8f849}{%
           family={3249–E},
           familyi={3\bibinithyphendelim E\bibinitperiod},
           given={Tech.},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{ee09f9fdfe615feaeca2f154e1c8f849}
      \strng{fullhash}{ee09f9fdfe615feaeca2f154e1c8f849}
      \strng{bibnamehash}{ee09f9fdfe615feaeca2f154e1c8f849}
      \strng{authorbibnamehash}{ee09f9fdfe615feaeca2f154e1c8f849}
      \strng{authornamehash}{ee09f9fdfe615feaeca2f154e1c8f849}
      \strng{authorfullhash}{ee09f9fdfe615feaeca2f154e1c8f849}
      \field{sortinit}{3}
      \field{sortinithash}{a37a8ef248a93c322189792c34fc68c9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This is a guide to the essential set of objective assessments of the optical and mechanical performance of a {TV}  camera lens that must be taken into consideration. Typical parameter values are provided.|}
      \field{day}{29}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Measurement and Analysis of the Performance of Camera Lenses}
      \field{urlday}{13}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{year}{1995}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{file}
      \verb Snapshot:/home/tristan/Zotero/storage/LSL6XCTT/tech3249.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://tech.ebu.ch/publications/tech3249
      \endverb
      \verb{url}
      \verb https://tech.ebu.ch/publications/tech3249
      \endverb
    \endentry
    \entry{noauthor_3d-bildverarbeitung_nodate}{online}{}
      \field{sortinit}{3}
      \field{sortinithash}{a37a8ef248a93c322189792c34fc68c9}
      \field{labeltitlesource}{title}
      \field{abstract}{Erfahren Sie mehr zum Thema 3D - Bildverarbeitung im Glossar von {STEMMER} {IMAGING}}
      \field{langid}{german}
      \field{title}{3D-Bildverarbeitung}
      \field{titleaddon}{{STEMMER} {IMAGING}}
      \field{urlday}{13}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb Snapshot:/home/tristan/Zotero/storage/ZR7GG4EE/3d-bildverarbeitung.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.stemmer-imaging.com/de-ch/grundlagen/3d-bildverarbeitung/
      \endverb
      \verb{url}
      \verb https://www.stemmer-imaging.com/de-ch/grundlagen/3d-bildverarbeitung/
      \endverb
    \endentry
    \entry{noauthor_a2a1920-160ucpro_nodate}{online}{}
      \field{sortinit}{a}
      \field{sortinithash}{a3dcedd53b04d1adfd5ac303ecd5e6fa}
      \field{labeltitlesource}{title}
      \field{title}{a2A1920-160ucPRO | Basler}
      \field{urlday}{28}
      \field{urlmonth}{4}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb a2A1920-160ucPRO | Basler:/home/tristan/Zotero/storage/M54TA6FS/a2a1920-160ucpro.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://docs.baslerweb.com/a2a1920-160ucpro
      \endverb
      \verb{url}
      \verb https://docs.baslerweb.com/a2a1920-160ucpro
      \endverb
    \endentry
    \entry{bajpai_cross-platform_nodate}{article}{}
      \name{author}{2}{}{%
        {{hash=6ad6555a5fed5515cead75612a54ef4c}{%
           family={Bajpai},
           familyi={B\bibinitperiod},
           given={Vaibhav},
           giveni={V\bibinitperiod}}}%
        {{hash=002aca6f1f59a79f2f61b09c3c62fca8}{%
           family={Perelman},
           familyi={P\bibinitperiod},
           given={Vladislav},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{7c89e3b09b31a68a05432ca108228aca}
      \strng{fullhash}{7c89e3b09b31a68a05432ca108228aca}
      \strng{bibnamehash}{7c89e3b09b31a68a05432ca108228aca}
      \strng{authorbibnamehash}{7c89e3b09b31a68a05432ca108228aca}
      \strng{authornamehash}{7c89e3b09b31a68a05432ca108228aca}
      \strng{authorfullhash}{7c89e3b09b31a68a05432ca108228aca}
      \field{sortinit}{B}
      \field{sortinithash}{8de16967003c7207dae369d874f1456e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper introduces a cross-platform low-cost system for 3D object reconstruction using a projection-based laser scanner. It uses contact-free measurement techniques for 3D object reconstruction and fast surface registration using Iterative Closest Point ({ICP}) [1]. The only hardware requirements are a simple hand-held laser line projector, a calibration rig and a standard camera. The camera is initially calibrated using Zhang’s camera calibration method so that its external and internal parameters are known. The visible intersection with the known background is used to ﬁnd the 3D pose of the laser plane. This laser plane is used to triangulate new 3D point coordinates of the object’s surface. The point clouds obtained are processed using the "3DTK - The 3D Toolkit" [2] which includes an automatic high-accurate registration process and a fast 3D viewer.}
      \field{langid}{english}
      \field{title}{A Cross-Platform Open Source 3D Object Reconstruction System using a Laser Line Projector}
      \field{pages}{5}
      \range{pages}{1}
      \verb{file}
      \verb Bajpai and Perelman - A Cross-Platform Open Source 3D Object Reconstruct.pdf:/home/tristan/Zotero/storage/TSNMSXSR/Bajpai and Perelman - A Cross-Platform Open Source 3D Object Reconstruct.pdf:application/pdf
      \endverb
    \endentry
    \entry{bart_accuracy_nodate}{article}{}
      \name{author}{3}{}{%
        {{hash=c7d5363a920c2714638e9535312685da}{%
           family={Bart},
           familyi={B\bibinitperiod},
           given={Boeckmans},
           giveni={B\bibinitperiod}}}%
        {{hash=7db8d345e981616feddab13c941f609e}{%
           family={Frank},
           familyi={F\bibinitperiod},
           given={Welkenhuyzen},
           giveni={W\bibinitperiod}}}%
        {{hash=197837db005b44235937bb614919dd1c}{%
           family={Jean-Pierre},
           familyi={J\bibinithyphendelim P\bibinitperiod},
           given={Kruth},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{ada6c7465db44e3ed9a0a9a7173ac439}
      \strng{fullhash}{ada6c7465db44e3ed9a0a9a7173ac439}
      \strng{bibnamehash}{ada6c7465db44e3ed9a0a9a7173ac439}
      \strng{authorbibnamehash}{ada6c7465db44e3ed9a0a9a7173ac439}
      \strng{authornamehash}{ada6c7465db44e3ed9a0a9a7173ac439}
      \strng{authorfullhash}{ada6c7465db44e3ed9a0a9a7173ac439}
      \field{sortinit}{B}
      \field{sortinithash}{8de16967003c7207dae369d874f1456e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents an accuracy verification test method for laser line scanners on coordinate measuring machines ({CMMs}). Recent evolutions improved laser line scanners to the extent that verification is increasingly important. A sphere beam with optically cooperative spheres is proposed as verification object. The ideal verification object excludes many influencing factors, e.g. specular reflection issues. The scanner sphere probing test describes a method to determine the scanner accuracy, the scanner ball bar test checks the integration of the scanner on the {CMM}. The experimental results show a scanner accuracy of about 8µm (sphere best fit {RMS} value) and a total accuracy below 14µm on a measuring length of 1m.}
      \field{langid}{english}
      \field{title}{Accuracy verification of a laser line scanner probe}
      \verb{file}
      \verb Bart et al. - Accuracy verification of a laser line scanner prob.pdf:/home/tristan/Zotero/storage/J3VZG3KR/Bart et al. - Accuracy verification of a laser line scanner prob.pdf:application/pdf
      \endverb
    \endentry
    \entry{pinhole_camera_model}{online}{}
      \field{sortinit}{C}
      \field{sortinithash}{4c244ceae61406cdc0cc2ce1cb1ff703}
      \field{labeltitlesource}{title}
      \field{abstract}{Camera calibration In our vision task at hand, recovering geometry in the scene, we will employ the pinhole camera model, which is a big simplification of the way images … - Selection from Mastering {OpenCV} 4 - Third Edition [Book]}
      \field{langid}{english}
      \field{note}{{ISBN}: 9781789533576}
      \field{title}{Camera calibration - Mastering {OpenCV} 4 - Third Edition [Book]}
      \field{titleaddon}{{OREILLY}}
      \field{urlday}{13}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb Snapshot:/home/tristan/Zotero/storage/XPJ2MHQA/848e4e77-32ec-499d-9945-cb0352e28236.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.oreilly.com/library/view/mastering-opencv-4/9781789533576/848e4e77-32ec-499d-9945-cb0352e28236.xhtml
      \endverb
      \verb{url}
      \verb https://www.oreilly.com/library/view/mastering-opencv-4/9781789533576/848e4e77-32ec-499d-9945-cb0352e28236.xhtml
      \endverb
    \endentry
    \entry{noauthor_camera_nodate}{online}{}
      \field{sortinit}{C}
      \field{sortinithash}{4c244ceae61406cdc0cc2ce1cb1ff703}
      \field{labeltitlesource}{title}
      \field{title}{Camera Calibration Toolbox for Matlab}
      \field{urlday}{29}
      \field{urlmonth}{3}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb Camera Calibration Toolbox for Matlab:/home/tristan/Zotero/storage/FRQKWFL9/calib_doc.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://www.vision.caltech.edu/bouguetj/calib_doc/
      \endverb
      \verb{url}
      \verb http://www.vision.caltech.edu/bouguetj/calib_doc/
      \endverb
    \endentry
    \entry{noauthor_camera_nodate-1}{online}{}
      \field{sortinit}{C}
      \field{sortinithash}{4c244ceae61406cdc0cc2ce1cb1ff703}
      \field{labeltitlesource}{title}
      \field{abstract}{Revision 1.2}
      \field{langid}{english}
      \field{title}{Camera Depth Testing Methodology}
      \field{titleaddon}{Intel® {RealSense}™ Developer Documentation}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb Snapshot:/home/tristan/Zotero/storage/4SCZ6SLV/camera-depth-testing-methodology.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://dev.intelrealsense.com/docs/camera-depth-testing-methodology
      \endverb
      \verb{url}
      \verb https://dev.intelrealsense.com/docs/camera-depth-testing-methodology
      \endverb
    \endentry
    \entry{dawson-howe_simple_1994}{article}{}
      \name{author}{2}{}{%
        {{hash=c65de7d35b8d9ebbded948203f2e464f}{%
           family={Dawson-Howe},
           familyi={D\bibinithyphendelim H\bibinitperiod},
           given={Kenneth\bibnamedelima M.},
           giveni={K\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=0b5ee53127c66270dfb58f6bfd85ec16}{%
           family={Vernon},
           familyi={V\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{21d6fd63b06943111f10fb7639e6908e}
      \strng{fullhash}{21d6fd63b06943111f10fb7639e6908e}
      \strng{bibnamehash}{21d6fd63b06943111f10fb7639e6908e}
      \strng{authorbibnamehash}{21d6fd63b06943111f10fb7639e6908e}
      \strng{authornamehash}{21d6fd63b06943111f10fb7639e6908e}
      \strng{authorfullhash}{21d6fd63b06943111f10fb7639e6908e}
      \field{sortinit}{D}
      \field{sortinithash}{c438b3d5d027251ba63f5ed538d98af5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A large number of cameras may be modeled quite accurately using the simple pinhole camera model, which may be defined either in terms of camera parameters or by the c matrix (which defines the mapping from 3D points to the image plane). We present formulations of the associated transformations between these two equivalent representations. We also introduce an inexpensive technique for calibrating a camera using a single two-plane calibration object, and employ a novel high-precision Hough transform technique for determinings calibration grid lines.©1994 John Wiley \& Sons Inc}
      \field{issn}{1098-1098}
      \field{journaltitle}{International Journal of Imaging Systems and Technology}
      \field{langid}{english}
      \field{note}{\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ima.1850050102}
      \field{number}{1}
      \field{title}{Simple pinhole camera calibration}
      \field{urlday}{13}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{volume}{5}
      \field{year}{1994}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1002/ima.1850050102
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/tristan/Zotero/storage/QNBJXDQ7/Dawson-Howe and Vernon - 1994 - Simple pinhole camera calibration.pdf:application/pdf;Snapshot:/home/tristan/Zotero/storage/RKB6W9T4/ima.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.1850050102
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/abs/10.1002/ima.1850050102
      \endverb
    \endentry
    \entry{grunnet-jepsen_best-known-methods_nodate}{article}{}
      \name{author}{3}{}{%
        {{hash=81e82c706525a3feccc93af8e18804d6}{%
           family={Grunnet-Jepsen},
           familyi={G\bibinithyphendelim J\bibinitperiod},
           given={Anders},
           giveni={A\bibinitperiod}}}%
        {{hash=9bc908dfa97875f240d5f02a09732465}{%
           family={Sweetser},
           familyi={S\bibinitperiod},
           given={John\bibnamedelima N},
           giveni={J\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=2a3dc3e374b1f938014cddab1a152d83}{%
           family={Woodfill},
           familyi={W\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{8fcd08e7004ec2faf6d71e605ffdbd17}
      \strng{fullhash}{8fcd08e7004ec2faf6d71e605ffdbd17}
      \strng{bibnamehash}{8fcd08e7004ec2faf6d71e605ffdbd17}
      \strng{authorbibnamehash}{8fcd08e7004ec2faf6d71e605ffdbd17}
      \strng{authornamehash}{8fcd08e7004ec2faf6d71e605ffdbd17}
      \strng{authorfullhash}{8fcd08e7004ec2faf6d71e605ffdbd17}
      \field{sortinit}{G}
      \field{sortinithash}{62eb2aa29549e4fdbd3cb154ec5711cb}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{Best-Known-Methods for Tuning Intel® {RealSense}™ D400 Depth Cameras for Best Performance}
      \field{pages}{10}
      \range{pages}{1}
      \verb{file}
      \verb Grunnet-Jepsen et al. - Best-Known-Methods for Tuning Intel® RealSense™ D4.pdf:/home/tristan/Zotero/storage/Z7TYJ45B/Grunnet-Jepsen et al. - Best-Known-Methods for Tuning Intel® RealSense™ D4.pdf:application/pdf
      \endverb
    \endentry
    \entry{liesen_lineare_2021}{book}{}
      \name{author}{2}{}{%
        {{hash=7e27769a9f513cd0df1e6aea45134814}{%
           family={Liesen},
           familyi={L\bibinitperiod},
           given={Jörg},
           giveni={J\bibinitperiod}}}%
        {{hash=9ea3694a4f993cf0fe21281abf196b87}{%
           family={Mehrmann},
           familyi={M\bibinitperiod},
           given={Volker},
           giveni={V\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Berlin, Heidelberg}%
      }
      \list{publisher}{1}{%
        {Springer Berlin Heidelberg}%
      }
      \strng{namehash}{fa7812116c584fde7fd7a58eb39ca3d7}
      \strng{fullhash}{fa7812116c584fde7fd7a58eb39ca3d7}
      \strng{bibnamehash}{fa7812116c584fde7fd7a58eb39ca3d7}
      \strng{authorbibnamehash}{fa7812116c584fde7fd7a58eb39ca3d7}
      \strng{authornamehash}{fa7812116c584fde7fd7a58eb39ca3d7}
      \strng{authorfullhash}{fa7812116c584fde7fd7a58eb39ca3d7}
      \field{sortinit}{L}
      \field{sortinithash}{dad3efd0836470093a7b4a7bb756eb8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{isbn}{978-3-662-62741-9 978-3-662-62742-6}
      \field{langid}{german}
      \field{shorttitle}{Lineare Algebra}
      \field{title}{Lineare Algebra: Ein Lehrbuch über die Theorie mit Blick auf die Praxis}
      \field{urlday}{5}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-662-62742-6
      \endverb
      \verb{file}
      \verb Liesen and Mehrmann - 2021 - Lineare Algebra Ein Lehrbuch über die Theorie mit.pdf:/home/tristan/Zotero/storage/DWJV9RWZ/Liesen and Mehrmann - 2021 - Lineare Algebra Ein Lehrbuch über die Theorie mit.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/978-3-662-62742-6
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/978-3-662-62742-6
      \endverb
    \endentry
    \entry{lourenco_intel_2021}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=7cbd5d6302f804ea1f41e1843ef69af2}{%
           family={Lourenço},
           familyi={L\bibinitperiod},
           given={Francisco},
           giveni={F\bibinitperiod}}}%
        {{hash=a291bfbded8f0f002c8e5b41b2c90623}{%
           family={Araujo},
           familyi={A\bibinitperiod},
           given={Helder},
           giveni={H\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Online Streaming, --- Select a Country ---}%
      }
      \list{publisher}{2}{%
        {{SCITEPRESS} - Science}%
        {Technology Publications}%
      }
      \strng{namehash}{9a6972c7c9a31ba434e98a125fda55c4}
      \strng{fullhash}{9a6972c7c9a31ba434e98a125fda55c4}
      \strng{bibnamehash}{9a6972c7c9a31ba434e98a125fda55c4}
      \strng{authorbibnamehash}{9a6972c7c9a31ba434e98a125fda55c4}
      \strng{authornamehash}{9a6972c7c9a31ba434e98a125fda55c4}
      \strng{authorfullhash}{9a6972c7c9a31ba434e98a125fda55c4}
      \field{sortinit}{L}
      \field{sortinithash}{dad3efd0836470093a7b4a7bb756eb8c}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{booktitle}{Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications}
      \field{eventtitle}{16th International Conference on Computer Vision Theory and Applications}
      \field{isbn}{978-989-758-488-6}
      \field{langid}{english}
      \field{shorttitle}{Intel {RealSense} {SR}305, D415 and L515}
      \field{title}{Intel {RealSense} {SR}305, D415 and L515: Experimental Evaluation and Comparison of Depth Estimation:}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{362\bibrangedash 369}
      \range{pages}{8}
      \verb{doi}
      \verb 10.5220/0010254203620369
      \endverb
      \verb{file}
      \verb Lourenço and Araujo - 2021 - Intel RealSense SR305, D415 and L515 Experimental.pdf:/home/tristan/Zotero/storage/B8R4K3MK/Lourenço and Araujo - 2021 - Intel RealSense SR305, D415 and L515 Experimental.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010254203620369
      \endverb
      \verb{url}
      \verb https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010254203620369
      \endverb
    \endentry
    \entry{nischwitz_bildverarbeitung_2020}{book}{}
      \name{author}{4}{}{%
        {{hash=31b46889fb689723b465a0afabd9cc5d}{%
           family={Nischwitz},
           familyi={N\bibinitperiod},
           given={Alfred},
           giveni={A\bibinitperiod}}}%
        {{hash=0bdd296ae3d3a3447fc5ca72080ab5ec}{%
           family={Fischer},
           familyi={F\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod}}}%
        {{hash=d054a15dda42f037200da05158fc505c}{%
           family={Haberäcker},
           familyi={H\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=bc439edb51082b148f1cb6ab6520d6c3}{%
           family={Socher},
           familyi={S\bibinitperiod},
           given={Gudrun},
           giveni={G\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Wiesbaden}%
      }
      \list{publisher}{1}{%
        {Springer Fachmedien Wiesbaden}%
      }
      \strng{namehash}{d34cabb31d1d2370ee1436a58445500f}
      \strng{fullhash}{36b05a139c9a10ebc24056ee5e87d470}
      \strng{bibnamehash}{d34cabb31d1d2370ee1436a58445500f}
      \strng{authorbibnamehash}{d34cabb31d1d2370ee1436a58445500f}
      \strng{authornamehash}{d34cabb31d1d2370ee1436a58445500f}
      \strng{authorfullhash}{36b05a139c9a10ebc24056ee5e87d470}
      \field{sortinit}{N}
      \field{sortinithash}{98cf339a479c0454fe09153a08675a15}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{isbn}{978-3-658-28704-7 978-3-658-28705-4}
      \field{langid}{german}
      \field{shorttitle}{Bildverarbeitung}
      \field{title}{Bildverarbeitung: Band {II} des Standardwerks Computergrafik und Bildverarbeitung}
      \field{urlday}{5}
      \field{urlmonth}{4}
      \field{urlyear}{2022}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1007/978-3-658-28705-4
      \endverb
      \verb{file}
      \verb Nischwitz et al. - 2020 - Bildverarbeitung Band II des Standardwerks Comput.pdf:/home/tristan/Zotero/storage/N4G2CKPI/Nischwitz et al. - 2020 - Bildverarbeitung Band II des Standardwerks Comput.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/978-3-658-28705-4
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/978-3-658-28705-4
      \endverb
    \endentry
    \entry{noauthor_opencv_nodate-1}{online}{}
      \field{sortinit}{O}
      \field{sortinithash}{ff8d4eeb5101e3cf3809959b3592d942}
      \field{labeltitlesource}{title}
      \field{title}{{OpenCV}: Camera Calibration}
      \field{urlday}{29}
      \field{urlmonth}{3}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb OpenCV\: Camera Calibration:/home/tristan/Zotero/storage/WT7V3BLT/tutorial_py_calibration.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html
      \endverb
      \verb{url}
      \verb https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html
      \endverb
    \endentry
    \entry{noauthor_opencv_nodate-2}{online}{}
      \field{sortinit}{O}
      \field{sortinithash}{ff8d4eeb5101e3cf3809959b3592d942}
      \field{labeltitlesource}{title}
      \field{title}{{OpenCV}: Camera Calibration and 3D Reconstruction}
      \field{urlday}{29}
      \field{urlmonth}{3}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb OpenCV\: Camera Calibration and 3D Reconstruction:/home/tristan/Zotero/storage/UBK7UIYL/group__calib3d.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html
      \endverb
      \verb{url}
      \verb https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html
      \endverb
    \endentry
    \entry{noauthor_opencv_nodate}{online}{}
      \field{sortinit}{O}
      \field{sortinithash}{ff8d4eeb5101e3cf3809959b3592d942}
      \field{labeltitlesource}{title}
      \field{title}{{OpenCV}: Color conversions}
      \field{urlday}{22}
      \field{urlmonth}{3}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb OpenCV\: Color conversions:/home/tristan/Zotero/storage/HRKN2HAW/imgproc_color_conversions.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://docs.opencv.org/4.x/de/d25/imgproc_color_conversions.html#color_convert_rgb_gray
      \endverb
      \verb{url}
      \verb https://docs.opencv.org/4.x/de/d25/imgproc_color_conversions.html#color_convert_rgb_gray
      \endverb
    \endentry
    \entry{otsu_tlreshold_nodate}{article}{}
      \name{author}{1}{}{%
        {{hash=4c9490b4888796e772e507d10bb89b3f}{%
           family={Otsu},
           familyi={O\bibinitperiod},
           given={Nobuyuki},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{4c9490b4888796e772e507d10bb89b3f}
      \strng{fullhash}{4c9490b4888796e772e507d10bb89b3f}
      \strng{bibnamehash}{4c9490b4888796e772e507d10bb89b3f}
      \strng{authorbibnamehash}{4c9490b4888796e772e507d10bb89b3f}
      \strng{authornamehash}{4c9490b4888796e772e507d10bb89b3f}
      \strng{authorfullhash}{4c9490b4888796e772e507d10bb89b3f}
      \field{sortinit}{O}
      \field{sortinithash}{ff8d4eeb5101e3cf3809959b3592d942}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A nonparametric and unsupervised method of automatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zeroth- and the first-order cumulative moments of the gray-level histogram. It is t straightforward to extend the method to multithreshold problems.}
      \field{langid}{english}
      \field{title}{A Tlreshold Selection Method from Gray-Level Histograms}
      \verb{file}
      \verb Otsu - A Tlreshold Selection Method from Gray-Level Histo.pdf:/home/tristan/Zotero/storage/MKCN88W5/Otsu - A Tlreshold Selection Method from Gray-Level Histo.pdf:application/pdf
      \endverb
    \endentry
    \entry{noauthor_prinzip_nodate}{online}{}
      \field{sortinit}{P}
      \field{sortinithash}{bb5b15f2db90f7aef79bb9e83defefcb}
      \field{labeltitlesource}{title}
      \field{title}{Prinzip der Triangulation}
      \field{titleaddon}{{Vision} {Doctor}}
      \field{urlday}{13}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb Prinzip der Triangulation:/home/tristan/Zotero/storage/6PRLYM95/prinzip-triangulation.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.vision-doctor.com/laser-beleuchtung/prinzip-triangulation.html
      \endverb
      \verb{url}
      \verb https://www.vision-doctor.com/laser-beleuchtung/prinzip-triangulation.html
      \endverb
    \endentry
    \entry{noauthor_rinntech_nodate}{online}{}
      \field{sortinit}{R}
      \field{sortinithash}{b9c68a358aea118dfa887b6e902414a7}
      \field{labeltitlesource}{title}
      \field{title}{{RINNTECH} - Technology for tree and wood analysis - Home}
      \field{urlday}{3}
      \field{urlmonth}{3}
      \field{urlyear}{2022}
      \field{urldateera}{ce}
      \verb{file}
      \verb RINNTECH - Technology for tree and wood analysis - Home:/home/tristan/Zotero/storage/ILTY7IZG/www.rinntech.de.html:text/html
      \endverb
      \verb{urlraw}
      \verb http://www.rinntech.de/
      \endverb
      \verb{url}
      \verb http://www.rinntech.de/
      \endverb
    \endentry
    \entry{song_multi-view_2019}{article}{}
      \name{author}{6}{}{%
        {{hash=64d1a4a683c51a92ede4376e626f2e17}{%
           family={Song},
           familyi={S\bibinitperiod},
           given={Limei},
           giveni={L\bibinitperiod}}}%
        {{hash=016ebd5be3e526f4c868c0a49b647953}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Siyuan},
           giveni={S\bibinitperiod}}}%
        {{hash=68b2c27a81e1144485b9448680660055}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Yangang},
           giveni={Y\bibinitperiod}}}%
        {{hash=fcaab3c9d4ec284771daa463b0e7e04d}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Xinjun},
           giveni={X\bibinitperiod}}}%
        {{hash=6f9e35741552e87a8396b0b3969da9f1}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Qinghua},
           giveni={Q\bibinitperiod}}}%
        {{hash=d4a87cb633ecaede2570f139ea851b6e}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Huaidong},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{b7ff6a13afd8b635047b96a28379e5f5}
      \strng{fullhash}{d7b20e64ace0cacf40d04d90be8db6a7}
      \strng{bibnamehash}{b7ff6a13afd8b635047b96a28379e5f5}
      \strng{authorbibnamehash}{b7ff6a13afd8b635047b96a28379e5f5}
      \strng{authornamehash}{b7ff6a13afd8b635047b96a28379e5f5}
      \strng{authorfullhash}{d7b20e64ace0cacf40d04d90be8db6a7}
      \field{sortinit}{S}
      \field{sortinithash}{c319cff79d99c853d775f88277d4e45f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A new solution to the high-quality 3D reverse modeling problem of complex surfaces for fine workpieces is presented using a laser line-scanning sensor. Due to registration errors, measurement errors, deformations, etc., a fast and accurate method is important in machine vision measurement. This paper builds a convenient and economic multi-view stereo ({MVS}) measurement system based on a linear stage and a rotary stage to reconstruct the measured object surface completely and accurately. In the proposed technique, the linear stage is used to generate the trigger signal and synchronize the laser sensor scanning; the rotary stage is used to rotate the object and obtain multi-view point cloud data, and then the multi-view point cloud data are registered and integrated into a 3D model. The measurement results show a measurement accuracy of 0.075 mm for a 360° reconstruction in 34 s, and some evaluation experiments were carried out to demonstrate the validity and practicability of the proposed technique.}
      \field{issn}{1424-8220}
      \field{journaltitle}{Sensors}
      \field{langid}{english}
      \field{month}{1}
      \field{note}{Number: 2 Publisher: Multidisciplinary Digital Publishing Institute}
      \field{number}{2}
      \field{title}{A Multi-View Stereo Measurement System Based on a Laser Scanner for Fine Workpieces}
      \field{urlday}{3}
      \field{urlmonth}{5}
      \field{urlyear}{2022}
      \field{volume}{19}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{381}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/s19020381
      \endverb
      \verb{file}
      \verb Full Text PDF:/home/tristan/Zotero/storage/GQL7AAYF/Song et al. - 2019 - A Multi-View Stereo Measurement System Based on a .pdf:application/pdf;Snapshot:/home/tristan/Zotero/storage/CL786NUB/htm.html:text/html
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/1424-8220/19/2/381
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/1424-8220/19/2/381
      \endverb
      \keyw{calibration,laser sensor,multi-view 3D reconstruction,point clouds,workpiece measurement}
    \endentry
    \entry{zhang_flexible_2000}{article}{}
      \name{author}{1}{}{%
        {{hash=5ee5d3d5470ac29a2e7c8df70ed54725}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Z.},
           giveni={Z\bibinitperiod}}}%
      }
      \strng{namehash}{5ee5d3d5470ac29a2e7c8df70ed54725}
      \strng{fullhash}{5ee5d3d5470ac29a2e7c8df70ed54725}
      \strng{bibnamehash}{5ee5d3d5470ac29a2e7c8df70ed54725}
      \strng{authorbibnamehash}{5ee5d3d5470ac29a2e7c8df70ed54725}
      \strng{authornamehash}{5ee5d3d5470ac29a2e7c8df70ed54725}
      \strng{authorfullhash}{5ee5d3d5470ac29a2e7c8df70ed54725}
      \field{sortinit}{Z}
      \field{sortinithash}{8f7b480688e809b50b6f6577b16f3db5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.}
      \field{issn}{1939-3539}
      \field{journaltitle}{{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
      \field{month}{11}
      \field{note}{Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence}
      \field{number}{11}
      \field{title}{A flexible new technique for camera calibration}
      \field{volume}{22}
      \field{year}{2000}
      \field{dateera}{ce}
      \field{pages}{1330\bibrangedash 1334}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/34.888718
      \endverb
      \verb{file}
      \verb IEEE Xplore Abstract Record:/home/tristan/Zotero/storage/4R4GYIB8/888718.html:text/html;IEEE Xplore Full Text PDF:/home/tristan/Zotero/storage/RJ9RAUBC/Zhang - 2000 - A flexible new technique for camera calibration.pdf:application/pdf
      \endverb
      \keyw{Cameras,Calibration,Closed-form solution,Computer simulation,Computer vision,Layout,Lenses,Maximum likelihood estimation,Nonlinear distortion,Testing}
    \endentry
    \entry{zollhofer_state_2018}{article}{}
      \name{author}{7}{}{%
        {{hash=3d2caa0b4dc1eee50a8a852c5c89bb5d}{%
           family={Zollhöfer},
           familyi={Z\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=a5adb02efccd0a8f6facf03ad6526673}{%
           family={Stotko},
           familyi={S\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod}}}%
        {{hash=18850acdd7cb4a3f27dee8c74322cbb0}{%
           family={Görlitz},
           familyi={G\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=02840f7b2a50f0d96ce13a913b71861d}{%
           family={Theobalt},
           familyi={T\bibinitperiod},
           given={Christian},
           giveni={C\bibinitperiod}}}%
        {{hash=3e07f51dbc36ece3b41bb5bcfe5b3b07}{%
           family={Nießner},
           familyi={N\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod}}}%
        {{hash=83ee01374e4d644d739e4382e249dcf8}{%
           family={Klein},
           familyi={K\bibinitperiod},
           given={Reinhard},
           giveni={R\bibinitperiod}}}%
        {{hash=f4195dc26f57b130791772dba2a6d789}{%
           family={Kolb},
           familyi={K\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{aedc98f249dffc6e6d0ac1000cb464e7}
      \strng{fullhash}{29fdd87e05052f0d176c865b530d74d3}
      \strng{bibnamehash}{aedc98f249dffc6e6d0ac1000cb464e7}
      \strng{authorbibnamehash}{aedc98f249dffc6e6d0ac1000cb464e7}
      \strng{authornamehash}{aedc98f249dffc6e6d0ac1000cb464e7}
      \strng{authorfullhash}{29fdd87e05052f0d176c865b530d74d3}
      \field{sortinit}{Z}
      \field{sortinithash}{8f7b480688e809b50b6f6577b16f3db5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The advent of aﬀordable consumer grade {RGB}-D cameras has brought about a profound advancement of visual scene reconstruction methods. Both computer graphics and computer vision researchers spend signiﬁcant eﬀort to develop entirely new algorithms to capture comprehensive shape models of static and dynamic scenes with {RGB}-D cameras. This led to signiﬁcant advances of the state of the art along several dimensions. Some methods achieve very high reconstruction detail, despite limited sensor resolution. Others even achieve real-time performance, yet possibly at lower quality. New concepts were developed to capture scenes at larger spatial and temporal extent. Other recent algorithms ﬂank shape reconstruction with concurrent material and lighting estimation, even in general scenes and unconstrained conditions. In this state-of-the-art report, we analyze these recent developments in {RGB}-D scene reconstruction in detail and review essential related work. We explain, compare, and critically analyze the common underlying algorithmic concepts that enabled these recent advancements. Furthermore, we show how algorithms are designed to best exploit the beneﬁts of {RGB}-D data while suppressing their often non-trivial data distortions. In addition, this report identiﬁes and discusses important open research questions and suggests relevant directions for future work.}
      \field{issn}{01677055}
      \field{journaltitle}{Computer Graphics Forum}
      \field{langid}{english}
      \field{month}{5}
      \field{number}{2}
      \field{shortjournal}{Computer Graphics Forum}
      \field{title}{State of the Art on 3D Reconstruction with {RGB}-D Cameras}
      \field{urlday}{2}
      \field{urlmonth}{3}
      \field{urlyear}{2022}
      \field{volume}{37}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{625\bibrangedash 652}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1111/cgf.13386
      \endverb
      \verb{file}
      \verb Zollhöfer et al. - 2018 - State of the Art on 3D Reconstruction with RGB-D C.pdf:/home/tristan/Zotero/storage/JSXIGCQZ/Zollhöfer et al. - 2018 - State of the Art on 3D Reconstruction with RGB-D C.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/10.1111/cgf.13386
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/10.1111/cgf.13386
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

