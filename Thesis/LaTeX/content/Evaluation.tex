\section{Evaluation}
		
		Der Lasertriangulationssensor wurde nun komplett vorgestellt. Es soll nun eine Evaluation folgen. Dabei wird zuerst eine Methode vorgestellt, die die Genauigkeit eines Scan berechnen kann. Nachdem werden zusätzlich aufgekommene Probleme und Schwierigkeiten erläutert.   
		\subsection{Testen von Genauigkeit}
		Ziel ist es die aufgenommene Punktewolke zu testen. Dazu muss das \glqq Ist\grqq{} mit einem \glqq Soll\grqq{} verglichen werden. Hierbei ist es schwierig ein \glqq Soll\grqq{} für einen beliebigen Scan zu finden. Für beispielsweise Aufnahmen von einem Holzstück oder andere Figuren müsste dann im vornherein schon ein genaues 3D-Modell vorliegen. Daraus ergibt sich, dass zum Vergleichen ein bekanntes Objekt gewählt werden muss. Grundsätzlich soll die relative Genauigkeit der Punkte ermittelt werden. Damit ist gemeint, wie genau die Punkte zueinander liegen. Die genaue Position im Raum ist erst einmal unabhängig zu betrachten. Eine gängige Methode dafür ist, das gescannte Objekt in die Punkte des Scan zu fitten und diese am besten zu den Punkten passende Version als \glqq Soll\grqq{} zu verwenden \citep{bart_accuracy_nodate} \citep{song_multi-view_2019}. Dabei ist es Notwendig ein Form zu wählen, die sich in Punkte fitten lässt. Am naheliegendsten sind dabei Geometrische Formen, wie zum Beispiel eine Ebene, eine Linie oder auch eine Kugel. Genau diese drei Formen wurden auch hier zur Genauigkeitsbestimmung gewählt. Ausgehend von einer Ebene ist die  Vorgehensweise demnach ein Scan einer planaren Fläche durchzuführen. In der gescannten Punktewolke wird dann eine \textit{Region of Interest} (ROI) definiert. Da durch den Versuchsaufbau auch einzelne Objekte links und recht der Linear-Führung aufgenommen werden (siehe \ref{chap:qual_ergeb}), muss die Punktewolke etwas zugeschnitten werden. In die resultierende Punktewolke, die nur noch die planare Fläche abbildet, wird dann, ähnlich wie in Kapitel \ref{chap:kalibrierung_extrinsisch} das Finden der Laser-Ebene, eine perfekt passende Ebene gefittet. Diese wird als \glqq Soll\grqq{} angesehen. Der eigentliche Vergleich findet dann statt, indem die Abstände der einzelnen Punkte zu der \glqq Soll\grqq-Ebene errechnet werden. Der Durchschnitt dieser Abstände ist der \textit{Root Mean Squeared Error} (RMS-Error). Dieser wird als Genauigkeits.Indikator verwendet. Dieselbe Methode wurde auch für eine einfache Linie und eine Kugel genutzt. Um eine höhere Genauigkeit der Messung zu erlangen, wird für eine bestimmte Szene dreimal ein Scan durchgeführt. Die gewollte Form wird dann über den Least-Squares-Algorithmus in die Punkte gefittet. Sobald das geschehen ist, können die Abstände der Punkte zu der Form berechnet werden. Hierbei beträgt die Distanz von dem Sensor zu dem Scan-Objekt 0,5 Meter. \newline
		Der erste Versuch ist mit einer Linie gemacht worden. Dazu wurde eine einzelne Laserlinie von einer geraden Fläche aufgenommen.  
		
		\begin{table}[h]
			\centering
			
			\begin{tabular}[h]{c|c|c|c||c}
				Messung & Scan 1 & Scan 2 & Scan 3 & Durchschnitt \\
				\hline
				RMS Error & 74,69 $\mu$m & 85,75 $\mu$m & 82,05 $\mu$m & 80,83 $\mu$m \\
				\hline
			\end{tabular}
		
			\caption{Messungen einer Linie}
			\label{tab:linie}
			
		\end{table}
	
		Die zweite Messung betrachtet eine Ebene. Der Versuchsaufbau selbst bietet dazu gute Möglichkeiten, da die Grundlage der Linear-Führung eine planare Grundlage ist. Diese wird in einem kompletten Scan-Ablauf aufgenommen. Die ROI ist dann eine zugeschnittene Punktewolke, in der nur noch die planare Grundlage dargestellt ist. In diese kann dann eine Ebene gefittet werden. Dieser Ablauf wird im Anhang \ref{anhang-f} in der Abbildung \ref{fig:plane_fit} gezeigt.
		
		\begin{table}[h]
			\centering
			
			\begin{tabular}[h]{c|c|c|c||c}
				Messung & Scan 1 & Scan 2 & Scan 3 & Durchschnitt \\
				\hline
				RMS Error & 121,92 $\mu$m & 121,59 $\mu$m & 113,37 $\mu$m & 118,96 $\mu$m \\
				\hline
			\end{tabular}
		
			\caption{Messungen einer Ebene}
			\label{tab:ebene}
			
		\end{table}
	
		Für die dritte Messung wurde eine Kugel benutzt. Der Unterschied zu den vorherigen Messungen ist, dass hier die tatsächliche Größe des Objektes mit evaluiert wird. Beim fitten einer Kugel wird Radius ausgegeben. Die verwendete Kugel hat einen Radius von 5 cm. Diese 5 cm sollten sich auch in der optimal gefitteten Kugel widerspiegeln. Zusätzlich wird der RMS Error berechnet. In Anhang \ref{anhang-f} wird in der Abbildung \ref{fig:sphere_fit} der Vorgang eines Scans der Messung gezeigt.
	
		\begin{table}[h]
			\centering
			
			\begin{tabular}[h]{c|c|c|c||c}
				Messung & Scan 1 & Scan 2 & Scan 3 & Durchschnitt \\
				\hline
				RMS Error & 356,08 $\mu$m & 354,62 $\mu$m & 339,45 $\mu$m & 350,05 $\mu$m \\
				\hline
				Radius & 4,80014 cm & 4,80705 cm & 4,80895 cm & 4,80538 cm \\
				\hline
			\end{tabular}
		
			\caption{Messungen einer Kugel}
			\label{tab:sphere}
			
		\end{table}
	
		An der durchgeführten Messung fällt auf, dass der Radius zu klein ist. Er ist zwischen 1 bis 2 Millimeter zu kurz. Der RMS Error für die gefittete Kugel ist jedoch im Vergleich zu den anderen Messungen in einem ähnlichen Mikrometer-Bereich. Die Varianz der Punkte um das \glqq Soll\grqq{} ist also gering, jedoch ist die Kugel an sich zu klein. Dabei sind 1 bis 2 Millimeter bei einem Soll von 50 Millimetern ein vergleichsweise großer Fehler. 
		
		\subsection{Bewertung}
		
		Die gemessenen Werte sollen nun bewertet werden, damit sie aussagekräftig sind. Grundsätzlich läss sich sagen, dass eine relative Genauigkeit der Punktewolken mit einen RMS Error von unter einem Millimeter für das Gesamtprojekt absolut ausreichend ist. Die Genauigkeit nimmt ab, je mehr Varianz in den zu scannenden Objekt ist. So ist der RMS Error bei eine Linie am geringsten und bei der Kugel am höchsten. Es lässt sich also vermuten, dass sehr verformte und unebene Objekte einen größeren RMS Error aufweisen, als die hier durchgeführten Messungen. Jedoch soll der Scanner Holzscheiben einscannen. Diese weisen eine glatte Oberfläche auf. Um letztendlich eine Ablauf-Pfad für eine Kamera zu finden, wäre der entwickelte Lasertriangulationssensor ausreichend.

		Für die im Gesamtprojekt alternativ verwendete RGB-D-Kamera „Intel RealSense d415“ kann ebenfalls der RMS Error errechnet werden \citep[Vgl.][]{noauthor_camera_nodate-1}. In \citep{grunnet-jepsen_best-known-methods_nodate} und \citep{lourenco_intel_2021} wurde neben vielen anderen Genauigkeits-Messungen der RMS Error für die „Intel RealSense d415“ gemessen und angegeben. Wobei hier immer eine Ebene als Messung benutzt wurde. Nach \citep{lourenco_intel_2021} liegt der RMS Error der RealSense bei eine Distanz von 0,5 Metern bei 2 Millimetern. Das würde bedeuten, dass die hier entwickelte Methode eine höhere Genauigkeit aufweist. Hier sei jedoch hervorgehoben, dass sich die Methode der Oberflächenrekonstruktion zu den hier entwickelten Scanner grundsätzlich unterscheidet. Der RealSense ist es möglich, mit einer Aufnahme die ganze Szene in 3D-Koordinaten umzuwandeln. Dem Lasertraingulationssensor ist es nur möglich den Querschnitt bzw. eine Laserlinie in 3D-Koordinaten zu übersetzten. Die Oberflächenrekonstruktion erhält man durch das aneinanderreihen der unterschiedlichen Querschnitt-Aufnahmen. Das wurde mit den Versuchsaufbau umgesetzt.
		
		\subsection{Probleme und Schwierigkeiten}\label{chap:probleme_schwierigkeiten}
		Bei der Entwicklung und beim Testen des Lasertriangulationssensors sind einige Probleme und Schwierigkeiten aufgetreten. Die ausschlaggebenden sollen hier angesprochen werden.
		
		$\underline{Die \; Beleuchtung}$
		
		Für das Erkennen der Farbinformation ist eine ausreichende Beleuchtung wichtig. Schnell passiert es, dass die Beleuchtung zu dunkel ausfällt und die Farben nicht gut erkennbar sind. Grundsätzlich ist das ein schnell behebbares Problem. Über Pylon kann die verwendete Basler-Kamera an die aktuelle Beleuchtung angepasst werden. Das Dilemma zum Thema der Beleuchtung ist viel mehr, dass je heller das Bild wird, um so weniger ist die Laserlinie erkennbar. An hellen Stellen, auch zu sehen bei den Qualitativen Ergebnissen in \ref{chap:qual_ergeb}, wird die Laserlinie nicht mehr erkannt. Dort ist es so hell, das kein ausreichender Unterschied in der Differenz des Bildpaares auffindbar ist. Gerade in \ref{subfig:scan_0} und \ref{subfig:scan_3} ist dieses Problem eindeutig am Rand der Unterlage des Holzes zu sehen. Sobald man die Kamera etwas dunkler Einstellt, werden die Farben des Holzes weniger gut erkannt. Es ist demnach notwendig die Kamera immer an die aktuelle Beleuchtung anzupassen. Die Anpassung muss so eingestellt sein, dass der Laser gut erkannt wird und gleichzeitig die Farben gut erkennbar sind. Ein automatisches Einstellen der Kamera ist bisher nicht implementiert.
		
		$\underline{\ddot{A}nderung \; im \; Bildpaar}$
		
		Der Lasertriangulationssensor ist sehr Anfällig auf jegliche Änderung der Szene, die zwischen den beiden Aufnahmen des Bildpaares stattfinden. Nach Plan darf sich hier nur das Einschalten des Laser ändern. Falls sich etwas anderes in Szene ändert, wird dies eindeutig in der Differenz der Bilder erkennbar sein. Da der Algorithmus immer bei der höchsten Intensität ansetzt ist er grundsätzlich robust und wird den Punkt der Laserlinie wählen. Sobald der Unterschied größer ist, kommt es zu ausschlaggebenden Fehlern. Auch hier ist die Beleuchtung wieder eine Fehlerquelle. Die Kamera kann ein Lichtflackern aufnehmen, welches für das menschliche Auge nicht sichtbar ist. Sobald dann ein Bild heller oder dunkler ausfällt, erhält man ein fehlerhaftes Differenz-Bild.
		
		$\underline{Fehlerquellen \; im \; Versuchsaufbau}$
		
		Als zusätzliche Fehlerquelle ist noch der Versuchsaufbau zu nennen. Die Möglichkeit den verwendeten Schrittmotor anzusteuern ist begrenzt. Hier ist es möglich, den Schrittmotor den Befehl sich zu bewegen zu senden. Dabei gibt es kein Feedback, welches erhalten werden kann, sobald die Bewegung abgeschlossen ist. Die Ausführung des Codes muss aber warten, dass die Bewegung tatsächlich abgeschlossen ist. Sonst könne es passieren, dass in der Ausführung der Triangulationssensor davon ausgeht, dass sich die Szene um einen Millimeter weiterbewegt hat, aber die eigentliche Bewegung ist noch nicht abgeschlossen. Die Ausführung und Ermittlung der Punktewolken ist dabei schnell genug , um zweimal innerhalb der Bewegung von einen Millimeter zu erfolgen. Der erste Fehler der hierbei passieren kann, ist, dass die Szene zwischen den Aufnahmen in Bewegung ist und dadurch das Differenz-Bild fehlerhaft ist. Der zweite Fehler ist, dass die Laserlinie in der resultierenden Punktewolke an falscher Position eingefügt wird. Für diese Fehlerquellen wurde der Versuchsaufbau schon so angepasst, dass im Code, nachdem der Befehl für die Bewegung gesendet wurde, eine Sekunde gewartet wird. So ist die Bewegung sicher abgeschlossen, bevor die nächsten Aufnahmen gemacht werden. Nachteil dadurch ist, dass der Scan vergleichsweise langsam aufgenommen wird. Trotzdem bleibt ein kleiner Fehler in der Position. Beim Anhängen der neuen Laserlinie wird genau ein Millimeter in x-Richtung aufaddiert. Hierbei ist ohne größeren Aufwand nicht überprüfbar, ob sich die Linear-Führung genau um einen Millimeter bewegt. Das hängt davon ab, wie genau der Schritt-Motor kalibriert ist. Die Varianz der Laserlinie ist gering und kann somit vernachlässigt werden. Es ist wahrscheinlicher, dass die Kalibrierung des Schritt-Motors für kleine Fehler verantwortlich ist. Diese Fehler können sich in der Oberflächenrekonstruktion aufaddieren und dazu führen, dass die gesamte Punktewolke in x-Richtung fehlerhaft ist. Hiermit wäre auch die der fehlerhafte Radius der gescannten Kugel erklärbar.
		
		$\underline{Spiegelung \; und \; schlechte \; Reflektion \; der \; Laserlinie}$
		
		Für einen Lasertriangulationssensor ist grundlegend vorausgesetzt, dass die Laserlinie auf den Objekt sichtbar ist. Das bedeutet, dass sie gut reflektiert wird. Wenn das nicht der Fall ist, kommt es zu Fehlern. Durchsichtige oder nicht reflektierende Oberflächen können vom Sensor nicht erfasst werden. Zu Fehlern kommt es auch, wenn sich das Laserlicht an einer Oberfläche spiegelt. Dadurch kann es passieren, dass rotes Licht an stellen erscheint, die gar nicht zur eigentlichen Laserlinie gehören. Dieses Licht kommt von dem Laser selbst und ist somit im Differenz-Bild eindeutig erkennbar. Da alle erfassten Pixel des Lasers auf die Laser-Ebene gespannt werden, erscheinen diese Fehlerhaften Stellen dann in der Oberflächenrekonstruktion über oder unter den Objekt als Rauschen. 